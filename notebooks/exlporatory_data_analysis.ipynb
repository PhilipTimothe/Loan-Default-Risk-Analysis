{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Load the dataset from the data directory\n",
    "file_path = \"../data/Credit Card Defaulter Prediction.csv\"  # Adjust path based on your file name\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop ID column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check data types and missing values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop ID column\n",
    "df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Check data types and missing values\n",
    "df.info()  \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there were missing values\n",
    "# For numerical features (BILL_AMT, PAY_AMT), replace missing values with the median:\n",
    "# df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# For categorical features (SEX, EDUCATION, MARRIAGE), replace missing values with the mode:\n",
    "# df.fillna(df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX'] = df['SEX'].map({'M': 1, 'F': 0})  # 1 = Male, 0 = Female\n",
    "\n",
    "df['MARRIAGE'] = df['MARRIAGE'].map({'Married': 1, 'Single': 2, 'Others': 3})\n",
    "\n",
    "df['EDUCATION'] = df['EDUCATION'].map({\n",
    "    'Graduate School': 1,\n",
    "    'University': 2,\n",
    "    'High School': 3,\n",
    "    'Others': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate removal\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "    'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
    "    'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "    'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "]\n",
    "\n",
    "df = df[important_features]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df[['LIMIT_BAL', 'AGE', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot of Continuous Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping extreme outliers\n",
    "df = df[df['AGE'] < 100]  # Remove unrealistic ages\n",
    "df['PAY_AMT1'] = df['PAY_AMT1'].clip(upper=df['PAY_AMT1'].quantile(0.99))  # Cap payments at 99th percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Correlation Between Features\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Credit Limits (LIMIT_BAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['LIMIT_BAL'], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Credit Limits (LIMIT_BAL)\")\n",
    "plt.xlabel(\"Credit Limit\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment Behavior Over Time (PAY_0 to PAY_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']])\n",
    "plt.title(\"Repayment Status Over Time\")\n",
    "plt.xlabel(\"Months (PAY_0 = Most Recent)\")\n",
    "plt.ylabel(\"Repayment Status (-1 = On Time, 1+ = Delayed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Maximum Delay\" Feature\n",
    "'''If a customer has delayed payments for multiple months, we can create a single max delay score'''\n",
    "\n",
    "df[\"Max_Delay\"] = df[[\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Debt Utilization Ratio Feature\n",
    "'''Meausre how much of the credit limit a customer is using'''\n",
    "\n",
    "df[\"Debt_Utilization\"] = df[\"BILL_AMT1\"] / df[\"LIMIT_BAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a average payment ratio\n",
    "'''A ratio of previous payments vs. billed amounts to identify those who only pay minimums.'''\n",
    "\n",
    "df[\"Avg_Payment_Ratio\"] = df[[\"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]].mean(axis=1) / df[[\"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\"]].mean(axis=1)\n",
    "df[\"Avg_Payment_Ratio\"].fillna(df[\"Avg_Payment_Ratio\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a High Risk Flag \n",
    "'''Mark customers as high risk if they had 3 or more months of delayed payments.'''\n",
    "\n",
    "df[\"High_Risk\"] = df[[\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"]].apply(lambda x: sum(x >= 2) >= 3, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "\n",
    "X = df[[\"LIMIT_BAL\", \"AGE\", \"Max_Delay\", \"Debt_Utilization\", \"Avg_Payment_Ratio\"]]  # Select meaningful features\n",
    "y = df[\"High_Risk\"]  # Predicting if a customer is high risk\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Issues with X values containing infinity values or a value too large for dtype'''\n",
    "# if infinity values replace\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# fill values with median\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance feature check\n",
    "\n",
    "feature_importance = pd.Series(model.coef_[0], index=X.columns).sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs']  # Different solvers to try\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(log_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Logistic Regression Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the best model\n",
    "best_log_model = grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
